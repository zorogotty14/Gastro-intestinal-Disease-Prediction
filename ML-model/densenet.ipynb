{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3529790c-2c28-4a0d-9c27-e51b673eed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d39187a-7695-45ca-b1d1-be6929e8c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "def load_and_preprocess_data(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, image_paths in data.items():\n",
    "        for path in image_paths:\n",
    "            img = cv2.imread(str(path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB format\n",
    "            img = cv2.resize(img, (224, 224))  # Resize image to VGG16 input size\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed657a5-55ba-483a-882a-c5eb8fd5da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = pathlib.Path(r\"C:\\Users\\gauth\\Desktop\\jobs\\EHR\\ML model\\kvasir-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4cbfac-c291-4e13-89dc-ea603dd2b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyed_ifted_polyps = list(path.glob('dyed-lifted-polyps/*'))\n",
    "dyed_resection_margins = list(path.glob('dyed-resection-margins/*'))\n",
    "esophagitis = list(path.glob('esophagitis/*'))\n",
    "normal_cecum = list(path.glob('normal-cecum/*'))\n",
    "normal_pylorus = list(path.glob('normal-pylorus/*'))\n",
    "normal_z_line = list(path.glob('normal-z-line/*'))\n",
    "polyps = list(path.glob('polyps/*'))\n",
    "ulcerative_colitis = list(path.glob('ulcerative-colitis/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e4e7cd-53c8-45a7-b8bb-ed9e80102661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'dyed-lifted-polyps' : dyed_ifted_polyps ,\n",
    "    'dyed-resection-margins' : dyed_resection_margins,\n",
    "    'esophagitis' : esophagitis,\n",
    "    'normal-cecum' : normal_cecum,\n",
    "    'normal-pylorus' : normal_pylorus,\n",
    "    'normal-z-line' : normal_z_line,\n",
    "    'polyps' : polyps,\n",
    "    'ulcerative-colitis' : ulcerative_colitis\n",
    "}\n",
    "\n",
    "polys_labels = {\n",
    "    0:'dyed-lifted-polyps',\n",
    "    1:'dyed-resection-margins',\n",
    "    2:'esophagitis',\n",
    "    3:'normal-cecum',\n",
    "    4:'normal-pylorus',\n",
    "    5:'normal-z-line',\n",
    "    6:'polyps',\n",
    "    7:'ulcerative-colitis'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c05404f-3d3f-4782-b4de-f9245ee3b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_and_preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ea94e2-973a-482d-b1b1-9fedea26e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02216def-fa38-437b-b3ab-f7afcee6b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c111f96-861f-48f5-b5df-fc524ebdccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DenseNet121 model with pre-trained weights\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build your classification model on top of the pre-trained DenseNet model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='softmax')  # Adjust the output units based on the number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6e6e68-02e0-4158-b56f-f4894b631ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Preprocess the data using DenseNet's preprocess_input function\n",
    "train_data_densenet = densenet_preprocess_input(train_data)\n",
    "val_data_densenet = densenet_preprocess_input(val_data)\n",
    "test_data_densenet = densenet_preprocess_input(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7adb2661-b794-42e8-ac45-6bfefce89e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 693ms/step - accuracy: 0.4581 - loss: 1.5342 - val_accuracy: 0.8000 - val_loss: 0.5121\n",
      "Epoch 2/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 673ms/step - accuracy: 0.7536 - loss: 0.5954 - val_accuracy: 0.8156 - val_loss: 0.4403\n",
      "Epoch 3/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 765ms/step - accuracy: 0.8294 - loss: 0.4425 - val_accuracy: 0.8594 - val_loss: 0.3671\n",
      "Epoch 4/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 758ms/step - accuracy: 0.8353 - loss: 0.3945 - val_accuracy: 0.8438 - val_loss: 0.3745\n",
      "Epoch 5/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 761ms/step - accuracy: 0.8736 - loss: 0.3310 - val_accuracy: 0.8453 - val_loss: 0.3711\n",
      "Epoch 6/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 756ms/step - accuracy: 0.8819 - loss: 0.3092 - val_accuracy: 0.8578 - val_loss: 0.3520\n",
      "Epoch 7/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 741ms/step - accuracy: 0.8825 - loss: 0.3027 - val_accuracy: 0.8578 - val_loss: 0.3419\n",
      "Epoch 8/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 773ms/step - accuracy: 0.8872 - loss: 0.2787 - val_accuracy: 0.8484 - val_loss: 0.3651\n",
      "Epoch 9/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 745ms/step - accuracy: 0.8690 - loss: 0.3196 - val_accuracy: 0.8609 - val_loss: 0.3366\n",
      "Epoch 10/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 740ms/step - accuracy: 0.9114 - loss: 0.2341 - val_accuracy: 0.8594 - val_loss: 0.3463\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data_densenet, train_labels_encoded, epochs=10, batch_size=32, validation_data=(val_data_densenet, val_labels_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebaf7a59-4a2e-4130-bfbc-1e3e45bfc169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 523ms/step - accuracy: 0.9069 - loss: 0.2758\n",
      "Test Accuracy: 0.8974999785423279\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data_densenet, test_labels_encoded)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febb9c38-afa4-422f-a1f4-1891aec6acf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │       \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │         \u001b[38;5;34m262,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)                     │           \u001b[38;5;34m2,056\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,830,874</span> (29.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,830,874\u001b[0m (29.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,456</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,456\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,914</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m528,914\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff4fd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = model.to_json()\n",
    "\n",
    "# Save the model's weights\n",
    "model_weights = model.get_weights()\n",
    "\n",
    "# Pickle the model architecture and weights\n",
    "with open('densenet_model_architecture.pkl', 'wb') as architecture_file:\n",
    "    pickle.dump(model_architecture, architecture_file)\n",
    "\n",
    "with open('densenet_model_weights.pkl', 'wb') as weights_file:\n",
    "    pickle.dump(model_weights, weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b498f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dense\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dense\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save the model using SavedModel format\n",
    "tf.saved_model.save(model, 'dense')\n",
    "print('Model Saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eab549c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=C:/Users/gauth/Desktop/jobs/EHR/ML model/dense. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(C:/Users/gauth/Desktop/jobs/EHR/ML model/dense, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/gauth/Desktop/jobs/EHR/ML model/dense\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Summary of the loaded model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:191\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=C:/Users/gauth/Desktop/jobs/EHR/ML model/dense. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(C:/Users/gauth/Desktop/jobs/EHR/ML model/dense, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('C:/Users/gauth/Desktop/jobs/EHR/ML model/dense')\n",
    "\n",
    "# Summary of the loaded model\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1c9c7-b115-4032-a942-353a0fb81859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC, AUC\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_pred_proba = model.predict(test_data_densenet)\n",
    "\n",
    "# Binarize the true labels\n",
    "y_test_binarized = label_binarize(test_labels_encoded, classes=np.unique(test_labels_encoded))\n",
    "\n",
    "# Calculate AUC for each class\n",
    "roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, multi_class='ovr')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for each class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2ea04-eb26-468a-8bfa-03b934ae2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model creation function\n",
    "def create_model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(8, activation='softmax')  # Adjust the output units based on the number of classes\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1583b89-f730-413d-986e-126379d471c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 8  # Update with the number of classes in your dataset\n",
    "\n",
    "# Perform cross-validation\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(train_data_densenet, train_labels_encoded)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "    \n",
    "    # Create ResNet50 model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train_data_densenet[train_index], train_labels_encoded[train_index], epochs=10, batch_size=32, validation_data=(train_data_densenet[val_index], train_labels_encoded[val_index]), verbose=1)\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_loss, val_acc = model.evaluate(train_data_densenet[val_index], train_labels_encoded[val_index], verbose=0)\n",
    "    print(f\"Validation Accuracy: {val_acc}\")\n",
    "    cv_scores.append(val_acc)\n",
    "\n",
    "# Calculate and print the mean cross-validation score\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Mean Cross-Validation Accuracy: {mean_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e644f-225d-4c7b-ade1-04db0bdf65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "predictions = model.predict(test_data_densenet)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_labels_encoded, predicted_labels)\n",
    "classes = [str(i) for i in range(8)]  # Assuming you have 8 classes\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611f580-4691-4264-b468-7edc282061b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
